# Project Report

## Abstract

Given a low-light image, the aim is to get a high quality, well-lit version of the image, while avoiding overexposure of parts of the scene. Our approach uses a combination of the frameworks used in the papers “[Learning to See in the Dark](https://arxiv.org/pdf/1805.01934.pdf)” and “[Burst photography for high dynamic range and low-light imaging on mobile cameras](http://graphics.stanford.edu/papers/hdrp/hasinoff-hdrplus-sigasia16.pdf)”. We use the U-Net neural network (used in [[1]](https://arxiv.org/pdf/1805.01934.pdf)) to get a well-lit image from an input low-light image and apply tone mapping (as in [[2]](http://graphics.stanford.edu/papers/hdrp/hasinoff-hdrplus-sigasia16.pdf)) to get the final image, which is not overexposed.


    
## Dependencies

python 2.7 
Tensorflow (>=1.1)
 Scipy
 Numpy
 Rawpy


## Running the code

Run the command:
python tune_Sony.py

## References

[1] [Learning to See in the Dark](https://arxiv.org/pdf/1805.01934.pdf)
[2] [Burst photography for high dynamic range and low-light imaging on mobile cameras](http://graphics.stanford.edu/papers/hdrp/hasinoff-hdrplus-sigasia16.pdf)


